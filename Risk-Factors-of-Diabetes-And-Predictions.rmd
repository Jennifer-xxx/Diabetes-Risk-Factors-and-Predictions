---
title: "Most Predictive Risk Factors of Type 2 Diabetes and Make Predictions"
author: "Yufei Liu"
output:
  html_document:
    toc: true
    toc_float: true
bibliography: ref.bib
---

This is the html version of the report. The PDF version of this report can be downloaded [here](Report.pdf).

```{r setup, message=FALSE, echo=FALSE, warning=FALSE}
set.seed(1007746003)
library(haven)
library(ggplot2)
library(ggstats)
library(gridExtra)
library(data.table)
library(kableExtra)
library(dplyr)
library(vtable)
library(corrplot)
library(jtools)
library(MASS)
library(caret)
library(gtsummary)
library(ggcorrplot)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(randomForest)
library(gbm)
library(xgboost)
library(sjPlot)
library(sjmisc)
library(sjlabelled)
library(regclass)
```

```{r load-data, message=FALSE, warning=FALSE, include=FALSE}
fn <- "https://www.cdc.gov/brfss/annual_data/2022/files/LLCP2022XPT.zip"
if (!file.exists("./data/LLCP2022.XPT ")){
  download.file(fn, destfile = "./data/LLCP2022XPT.zip")
  unzip("./data/LLCP2022XPT.zip", exdir = "./data")
}

project_data <- read_xpt("./data/LLCP2022.XPT ")

dim(project_data)
sum(is.na(project_data))
```

# 1. Introduction

Diabetes is a serious chronic disease all over the world. The global prevalence of diabetes continues to skyrocket, exacerbated by a lack of awareness of the disease. In the US, approximately 38.4 million people, which is 11.6% of the US population, had diabetes in 2021 from the statistics in the National Diabetes Statistics Report [@CDC-report] by the Centers for Disease Control and Prevention (CDC).

For long, researchers have been focused on examining the diabetes risks and predicting diabetes in the early stage. There are 2 main kinds of diabetes. By Cafasso [@type1vs2], type 1 diabetes is an autoimmune disease likely caused by genes and viruses, while type 2 diabetes is possibly caused by lifestyle factors such as obesity and lack of exercise. Therefore, most researches focus on the potential causes of type 2 diabetes since it is more preventive. Since one of my family members has type 2 diabetes, I'm also interested in the cause of type 2 diabetes and what we can do to prevent ourselves from having type 2 diabetes. Therefore, I would like to explore **the risk factors that are most predictive of type 2 diabetes and predict whether an individual has type 2 diabetes** given the information provided in the Behavioral Risk Factor Surveillance System (BRFSS) survey data [@BRFSS-data].

The BRFSS survey, initiated by the CDC, is a state-based cross-sectional telephone survey used to gather prevalence data on risk behaviors and preventive health practices among adult U.S. residents. Since the data is developing annually, I'll use the newest available BRFSS survey data in 2022 to explore my questions. The dataset contains 445132 rows and 328 columns. Each row corresponds to a respondent. The columns contain the basic information of the respondents, their health conditions, answers to the health-related questions in the survey, and most importantly, whether the respondents have diabetes. Since there are too many columns and my analysis will only use a small portion of the potentially important risk factors, I will not list all the variables and would explain the used variables in the later sections. The meanings of all the variables and their possible values are listed on the documentation website [@BRFSS-data]. 

# 2. Methods

## 2.1 Keep only columns of interest and rename the variables
From the relevant paper about some of the potential risk factors with diabetes [@risk-factors] and the available columns of the survey data, I selected the below columns for future analysis and renamed them for easy understanding.

- Question (`column name`): possible values (meaning of the value) > **renamed column name**

**Response variable:**

- (Ever told) you had diabetes (`DIABETE4`): 1 (Yes), 2 (Only during pregnancy), 3 (No), 4 (No, pre-diabetes or borderline diabetes), 7 (Don’t know/Not Sure), 9 (Refused) > **diabetes**
- According to your doctor or other health professional, what type of diabetes do you have? (`DIABTYPE`): 1 (Type 1), 2 (Type 2), 7 (Don’t know/Not Sure), 9 (Refused) > **diabetes_type**

**Predictor variables:**

- Imputed race/ethnicity value (`_IMPRACE`): 1 (White), 2 (Black), 3(Asian), 4 (American Indian/Alaskan Native), 5 (Hispanic), 6 (Other race) > **race**
- Sex of Respondent (`SEXVAR`): 1 (Male), 2(Female) > **sex**
- Reported age in five-year age categories (`_AGEG5YR`): 1 (18 - 24), 2 (25 - 29), 3 (30 -34), 4 (35-39), 5 (40-44), 6 (45 - 49), 7 (50 - 54), 8 (55 - 59), 9 (60 - 64), 10 (65 - 69), 11 (70 - 74), 12 (75 - 79), 13 (80 or older), 14 (Don’t know/Refused/Missing) > **age**
-  Level of education completed (`_EDUCAG`): 1	(Did not graduate High School), 2	(Graduated High School), 3	(Attended College or Technical School), 4	(Graduated from College or Technical School), 9 (Don’t know/Not sure/Missing) > **education**
- Annual household income from all sources (`_INCOMG1`): 1 (Less than \$15,000), 2 (\$15,000 to < \$25,000), 3 (\$25,000 to < \$35,000), 4 (\$35,000 to < \$50,000), 5 (\$50,000 to < \$100,000), 6	(\$100,000 to < \$200,000), 7	(\$200,000 or more), 9	(Don’t know/Not sure/Missing) > **income**
- Body Mass Index (`_BMI5`): 1 - 9999	(corresponding BMI) > **bmi**
- On average, how many hours of sleep do you get in a 24-hour period? (`SLEPTIM1`): 1 - 24 (Number of hours), 77 (Don’t know/Not Sure), 99 (Refused) > **sleep**
- Have you smoked at least 100 cigarettes in your entire life? (`SMOKE100`): 1 (Yes), 2 (No), 7 (Don't know/Not Sure), 9 (Refused) > **smoke**
- Exercise in Past 30 Days (`EXERANY2`): 1 (Yes), 2 (No), 7 (Don't know/Not Sure), 9 (Refused) > **exercise**
- (Ever told) you had a stroke (`CVDSTRK3`): 1 (Yes), 2 (No), 7 (Don't know/Not Sure), 9 (Refused) > **stroke**
- (Ever told) you had coronary heart disease (CHD) or myocardial infarction (MI) (`_MICHD`): 1 (Yes), 2 (No) > **heart_disease**
- Heavy drinkers - adult men having more than 14 drinks per week and adult women having more than 7 drinks per week) (`_RFDRHV8`): 1 (No), 2 (Yes), 9 (Don’t know/Refused/Missing) > **alcohol**
- Would you say that in general, your health is (`GENHLTH`): 1	(Excellent), 2	(Very good), 3	(Good), 4	(Fair),	5	(Poor), 7 (Don't know/Not Sure), 9 (Refused) > **health**

```{r select-columns, include=FALSE}
data <- data.table(diabetes = project_data$DIABETE4,
                   diabetes_type = project_data$DIABTYPE,
                   race = project_data$`_IMPRACE`,
                   sex = project_data$SEXVAR,
                   age = project_data$`_AGEG5YR`,
                   education = project_data$`_EDUCAG`,
                   income = project_data$`_INCOMG1`,
                   bmi = project_data$`_BMI5`,
                   sleep = project_data$SLEPTIM1,
                   smoke = project_data$SMOKE100,
                   exercise = project_data$EXERANY2,
                   stroke = project_data$CVDSTRK3,
                   heart_disease = project_data$`_MICHD`,
                   alcohol = project_data$`_RFDRHV8`,
                   health = project_data$GENHLTH)
dim(data)
```

The filtered dataset has 445132 rows and 15 columns as mentioned above.

## 2.2 Check the import issues, modify and clean the values
Firstly, I checked the values in the variables and found that they are consistent with the description on the website.

Then, I marked all values indicating Don’t know/Not Sure or Refused as NA since they don't provide useful information to the question. Also, I changed all number of 2 representing no into 0 to make it more consistent with our usage of data.

Since `diabetes` and `diabetes_type` are the important response variables to be predicted, we can check the counts per category in _Table 1_. From _Table 1_, we can see that there are much more people without diabetes than other categories of diabetes. And among all people with diabetes, most of them are of type 2 diabetes. Pre-diabetes or borderline diabetes (4) indicates a high risk of developing diabetes in the future [@prediabetes]. Having diabetes only during pregnancy is called gestational diabetes, which can be caused by different factors and increases the risk of having type 2 diabetes [@gestational]. Therefore, the lifestyles of people who diagnosed as pre-diabetes or borderline diabetes or diabetes only during pregnancy may not be considered representative of healthy people. And we only compare people with type 2 diabetes (`diabetes` = 1 and `diabetes_type` = 2) with people who claimed not having diabetes (`diabetes` = 3).

```{r echo=FALSE}
data %>%
  count(diabetes, diabetes_type) %>%
  kable(caption = "Table 1: Counts of Diabetes and Diabetes Type for Each Category") %>%
  kable_paper("hover", full_width = FALSE)
```

- `diabetes`: change the value to 0 for no diabetes, 1 for having type 2 diabetes, pre-diabetes, or borderline diabetes. Remove `diabetes_type` column. Remove the missing values.

Lastly, for some specific variables, I made the following modifications. Some of the categorical variables are ordinal and can be represented by numbers in order. Therefore, I keep the numbers to make the models easier to fit and interpret.

- `race`: change the numbers to the corresponding race category in characters since it's nominal. Here, American Indian/Alaska Native is marked as as AI/AN for short.
- `sex`: change 1 to "Male", and 2 to "Female" for easier understanding.
- `bmi`: divide all values by 100.
- `healthy_sleep`: add a variable named `healthy_sleep` that categorize >= 7 hours and <= 10 hours of sleep as 1 and other as 0. This is because researches suggest that regularly sleeping for more than 10 hours a day indicates oversleeping, which may indicate an underlying health condition [@oversleep], and adults need 7 or more hours a night of sleep for good health. [@undersleep]

```{r clean-values, include=FALSE}
# diabetes
print("Diabetes:")
unique(data[, diabetes])
data[diabetes == 7 | diabetes == 9, diabetes := NA]
data <- data[(diabetes == 1 & diabetes_type == 2) | diabetes == 3]
data[, diabetes := as.character(diabetes)]
data[diabetes == "1" & diabetes_type == 2, diabetes := "Positive"]
data[diabetes == "3", diabetes := "Negative"]
data <- data[, diabetes_type := NULL]
unique(data[, diabetes])

# race
print("Race:")
unique(data[, race])
data[, race := as.character(race)]
data[race == "1", race := "White"]
data[race == "2", race := "Black"]
data[race == "3", race := "Asian"]
data[race == "4", race := "AI/AN"]
data[race == "5", race := "Hispanic"]
data[race == "6", race := "Other"]
unique(data[, race])

# sex
print("Sex:")
unique(data[, sex])
data[, sex := as.character(sex)]
data[sex == "1", sex := "Male"]
data[sex == "2", sex := "Female"]
unique(data[, sex])

# age
print("Age:")
unique(data[, age])
data[age == 14, age := NA]
unique(data[, age])

# education
print("Education:")
unique(data[, education])
data[education == 9, education := NA]
unique(data[, education])

# income
print("Income:")
unique(data[, income])
data[income == 9, income := NA]
unique(data[, income])

# bmi
print("BMI:")
summary(data$bmi)
data[, bmi := bmi / 100]
summary(data$bmi)

# sleep
print("Sleep:")
unique(data[, sleep])
data[sleep == 77 | sleep == 99, sleep := NA]
data[sleep < 7 | sleep > 10, sleep := 0]
data[sleep >= 7 & sleep <= 10, sleep := 1]
unique(data[, sleep])

# smoke
print("Smoke:")
unique(data[, smoke])
data[smoke == 7 | smoke == 9, smoke := NA]
data[smoke == 2, smoke := 0]
unique(data[, smoke])

# exercise
print("Exercise:")
unique(data[, exercise])
data[exercise == 7 | exercise == 9, exercise := NA]
data[exercise == 2, exercise := 0]
unique(data[, exercise])

# stroke
print("Stroke:")
unique(data[, stroke])
data[stroke == 7 | stroke == 9, stroke := NA]
data[stroke == 2, stroke := 0]
unique(data[, stroke])

# heart_disease
print("Heart disease:")
unique(data[, heart_disease])
data[heart_disease == 2, heart_disease := 0]
unique(data[, heart_disease])

# alcohol
print("Alcohol:")
unique(data[, alcohol])
data[alcohol == 9, alcohol := NA]
data[alcohol == 1, alcohol := 0]
data[alcohol == 2, alcohol := 1]
unique(data[, alcohol])

# health
print("Health:")
unique(data[, health])
data[health == 7 | health == 9, health := NA]
unique(data[, health])
```

## 2.3 Check rates of missing values in the variables.
```{r missing-rate, include=FALSE}
# Overall missing rate
dim(data)
mean(is.na(data))

# Missing rate for the variables
M <- colMeans(is.na(data))
M[M>0]

# Remove all NA values
data_cleaned <- na.omit(data)
dim(data_cleaned)

# Missing rate for the variables after removing some NAs
M_cleaned <- colMeans(is.na(data_cleaned))
M_cleaned
```

The overall missing rate of the data is about 4.07%. The missing rates of most variables are below 10%, except that `bmi` has a missing rate of 10.98%, `alcohol` has a missing rate of 11.27%, and `income` has a missing rate of 21.54%. Since our dataset has 379281 rows after cleaning missing data of `diabetes`, which is fairly large, removing some rows with NA values may not affect the result too much. Therefore, I removed all the NA values to make the future analysis easier to perform. The resulting dataset has 256564 rows and 14 columns.

## 2.4 Change the type of key variables from string to factor as appropriate.
```{r factor, include=FALSE}
# Check the type of key variables
sapply(data_cleaned, class)

# Change the type of key variables to factor
data_cleaned[, race := as.factor(race)]
data_cleaned[, race := relevel(race, ref="White")]
data_cleaned[, sex := as.factor(sex)]
data_cleaned[, diabetes := as.factor(diabetes)]
data_cleaned[, diabetes := relevel(diabetes, ref="Negative")]

# Check the changed type of key variables
sapply(data_cleaned, class)
```

Here, I converted the data type of `race` and `sex` from character to factor. Also, I releveled `race` so that the reference group in the future fitted regression models is **White**, the majority of `race`.

## 2.5 Identify and handle any outliers or imbalanced dataset.

From 2.2, I've already checked that the data corresponds to the description on the website. After the modification, all categorical variables (including numeric variables representing categories) now only contain the specified values, which is desired. Therefore, only `bmi`may possibly contain unreasonable data or outliers.

### 2.5.1 Identify outliers for BMI

```{r outliers-bmi, echo=FALSE}
# Identify outliers for bmi
par(mfrow = c(2, 2))
boxplot(data_cleaned[, bmi], xlab = "BMI", main = "Boxplot for BMI", horizontal=TRUE)
hist(data_cleaned[, bmi], xlab = "BMI", main = "Histogram for BMI")

data_cleaned <- data_cleaned[bmi < 80]
boxplot(data_cleaned[, bmi], xlab = "BMI", main = "Boxplot for BMI < 80", horizontal=TRUE)
hist(data_cleaned[, bmi], xlab = "BMI", main = "Histogram for BMI < 80")

mtext("Figure 1: Distributions of BMI", side = 3, line = -1, outer = TRUE)
```

From the boxplot and histogram for `bmi` in _Figure 1_, we can see that the data is right-skewed with multiple outliers with values above 45. From the paper [@bmi], individuals are classified based on body mass index (BMI) into categories such as underweight (BMI < 18.5), normal weight (BMI 18.5 to < 25), overweight (BMI 25 to <30), and obese (BMI $\geq$ 30), with obesity further categorized into grades: grade 1 (BMI 30 to <35), grade 2 (BMI 35 to <40), and grade 3 (BMI $\geq$ 40). This paper talks about a fatal case of super-super obesity (BMI > 80), which indicates that such cases are rare. Therefore, I removed all rows with BMI $\geq$ 80 so that the results are more general. From the plots of the dataset with BMI < 80 in _Figure 1_, we can see that the distribution of BMI is still right-skewed with most data between 20 and 40.

### 2.5.2 Handle imbalanced dataset

From _Table 1_, there are much more people without diabetes than with diabetes, which may affect the performance of the model. Therefore, downsampling the majority class is performed on the dataset to make the two classes contain equal number of observations.

```{r outliers-alcohol, include=FALSE}
# Identify the class proportions for diabetes
table(data_cleaned$diabetes)

# Downsample the class without diabetes to the same number of the class with diabetes
set.seed(1007746003)
data_downsampled <- downSample(x = subset(data_cleaned, select = -diabetes),
                               y = data_cleaned$diabetes,
                               yname = "diabetes") %>%
  as.data.table()

table(data_downsampled$diabetes)
```

```{r dim, eval=FALSE, include=FALSE}
dim(data_downsampled)
```

After removing all the outliers and downsampling the dataset, the dataset now contains 14316 rows and 14 columns.

```{r save-data, eval=FALSE, include=FALSE}
# Save the cleaned dataset as clean_data.csv in the data folder
write.csv(data_downsampled, "./data/clean_data.csv", row.names=FALSE)
```

## 2.6 Tools used for data analysis
- Summary tables are used to summarize the constitutions of the dataset and find out the proportion of each kind of data in the whole dataset.
- Proportional barplots, and boxplots are used to visualize the distributions of each variable given diabetes and find potential patterns in the distributions.
- Correlation matrix and its plot are used to find the potential correlation between the predictor variables and the response variable `diabetes`. If the correlations between predictors are too high, multicollinearity need to be checked after fitting the linear model using variance inflation factor (VIF).
- Split the dataset into training and testing (70-30%) for model performance evaluation.
- A simple logistic regression model of all predictor variables is fitted to find the potential relationships between the predictor variables and the response variable `diabetes`. stepAIC is performed to find the model with the smallest AIC.
- A classification tree is fitted to predict `diabetes`. Then, it is pruned based on the optimal complexity parameter.
- Bagging, random forests, gradient boosting machine, and xgboost with grid search are trained to predict diabetes. The variable importance plots indicate the important predictors of `diabetes` suggested by the corresponding model.
- The performances of all models are evaluated and compared with each other to select the best model. The important factors indicated by each model are combined to generate the final most predictive risk factors.

```{r head, eval=FALSE, include=FALSE}
# Take a look at the preprocessed data
head(data_downsampled) %>%
  kable(caption = "Head of the Preprocessed Data") %>%
  kable_paper("hover", full_width = FALSE)
```


# 3. Results

## 3.1 Data Summary

### 3.1.1 Summary statistics for numerical variables

The minimum, maximum, mean, standard deviation, count, and the quantiles of `bmi` are listed in _Table 2_ below.
```{r summary_num, echo=FALSE}
sumtable(data_cleaned, vars = c("bmi"),
         summ.names=c("Count", "Mean", "Standard Deviation", "Min", "1st Quantile", "Median", "3rd Quantile", "Max"),
         title="Table 2: Summary Statistics for BMI",
         add.median = TRUE,
         simple.kable = TRUE)
```

From _Table 2_, we can see that `bmi` fall in the range that I designed before, and the mean (28) is a bit larger than the median (27), indicating the slightly right-skewed distribution as shown in _Figure 1_.

### 3.1.2 Summary statistics for categorical variables

```{r vis, include=FALSE}
# Make dataset for visualization
data_vis <- copy(data_downsampled)

data_vis[, exercise := as.character(exercise)]
data_vis[exercise == "1", exercise := "Exercised"]
data_vis[exercise == "0", exercise := "No Exercise"]
data_vis[, exercise := as.factor(exercise)]

data_vis[, stroke := as.character(stroke)]
data_vis[stroke == "1", stroke := "Had Stroke"]
data_vis[stroke == "0", stroke := "Never Had Stroke"]
data_vis[, stroke := as.factor(stroke)]

data_vis[, heart_disease := as.character(heart_disease)]
data_vis[heart_disease == "1", heart_disease := "Had Heart Disease"]
data_vis[heart_disease == "0", heart_disease := "Never Had Heart Disease"]
data_vis[, heart_disease := as.factor(heart_disease)]

data_vis[, education := as.character(education)]
data_vis[education == "1", education := "Did not graduate High School"]
data_vis[education == "2", education := "Graduated High School"]
data_vis[education == "3", education := "Attended College or Technical School"]
data_vis[education == "4", education := "Graduated from College or Technical School"]
data_vis[, education := as.factor(education)]

data_vis[, health := as.character(health)]
data_vis[health == "1", health := "Excellent"]
data_vis[health == "2", health := "Very good"]
data_vis[health == "3", health := "Good"]
data_vis[health == "4", health := "Fair"]
data_vis[health == "5", health := "Poor"]
data_vis[, health := as.factor(health)]

data_vis[, age := as.character(age)]
data_vis[age == "1", age := "18 - 24"]
data_vis[age == "2", age := "25 - 29"]
data_vis[age == "3", age := "30 - 34"]
data_vis[age == "4", age := "35 - 39"]
data_vis[age == "5", age := "40 - 44"]
data_vis[age == "6", age := "45 - 49"]
data_vis[age == "7", age := "50 - 54"]
data_vis[age == "8", age := "55 - 59"]
data_vis[age == "9", age := "60 - 64"]
data_vis[age == "10", age := "65 - 69"]
data_vis[age == "11", age := "70 - 74"]
data_vis[age == "12", age := "75 - 79"]
data_vis[age == "13", age := "80 or older"]
data_vis[, age := as.factor(age)]

data_vis[, income := as.character(income)]
data_vis[income == "1", income := "Less than $15,000"]
data_vis[income == "2", income := "$15,000 to < $25,000"]
data_vis[income == "3", income := "$25,000 to < $35,000"]
data_vis[income == "4", income := "$35,000 to < $50,000"]
data_vis[income == "5", income := "$50,000 to < $100,000"]
data_vis[income == "6", income := "$100,000 to < $200,000"]
data_vis[income == "7", income := "$200,000 or more"]
data_vis[, income := as.factor(income)]

data_vis[, sleep := as.character(sleep)]
data_vis[sleep == "1", sleep := "Sleep between 7 and 10 hours (inclusive)"]
data_vis[sleep == "0", sleep := "Sleep < 7 or > 10 hours"]
data_vis[, sleep := as.factor(sleep)]

data_vis[, smoke := as.character(smoke)]
data_vis[smoke == "0", smoke := "Smoked No More Than 100 Cigarettes"]
data_vis[smoke == "1", smoke := "Smoked More Than 100 Cigarettes"]
data_vis[, smoke := as.factor(smoke)]

data_vis[, alcohol := as.character(alcohol)]
data_vis[alcohol == "0", alcohol := "Non-Heavy Drinker"]
data_vis[alcohol == "1", alcohol := "Heavy Drinker"]
data_vis[, alcohol := as.factor(alcohol)]
```

```{r contingency-table, echo=FALSE, message=FALSE}
# Generate the contingency table
table3 <- tbl_summary(data_vis,
                      include = c(race, sex, age, education, income, sleep, smoke,
                                  exercise, stroke, heart_disease, alcohol, health),
                      by = diabetes) %>%
  add_p() %>%
  modify_header(label = "**Variable**") %>%
  modify_caption("**Table 3: Summary Statistics for Categorical Variables**")  %>%
  bold_labels() %>%
  add_overall()
table3
```

From _Table 3_, the distributions of `sex` and `smoke` are roughly the same among the two categories, which is a good sign indicating unbiasedness of the predictor in the dataset.  
The distributions of `age`, `income`, and `health` are normal with most people in the middle categories and fewer people in the extreme categories, which corresponds with the real-world situation as expected.  
However, there are much more white people than other races, and much more people who had appropriate hours of sleep or exercised or never had stroke or heart disease than the opposite. This also accords with the actual situation since the survey is performed in the US and there are more healthy people in the world. Additionally, education proportion suggests that this study population is on the more well educated side than average. This bias is not present in a study that explores the relationship between diabetes and education [@education], which is of concern. All of these may present bias in the analysis, which may require future investigation.
All Pearson’s Chi-squared tests except sex have a p-value of less than 0.001, indicating strong evidence against the null hypothesis that the observed differences within the categories appear by chance. Sex may not be a good indicator from the test.

```{r save-vis-data, eval=FALSE, include=FALSE}
# Save the dataset for visualization as vis_data.csv in the data folder
write.csv(data_vis, "./data/vis_data.csv", row.names=FALSE)
```


## 3.2 Data Visualization

All data visualization and analysis can be found on the [website](https://jennifer-xxx.github.io/Diabetes-Risk-Factors-and-Predictions/visualization.html) **Home** and **Visualization** page. To distinguish the plot on the website and the figures in the report, I would use _Plot + number_ to represent the plots on the website and _Figure + number_ to represent figures in the report.

From the _Plot 1_, we can figure out the distributions of BMI among people with diabetes and people without diabetes. The boxplot suggests that `bmi` is positively correlated with diabetes since people with diabetes tend to have higher BMI.

_Plot 2_ shows the distribution of age for people with diabetes and people without diabetes. The plot indicates that `age` may have a positive relationship with diabetes since most people with diabetes have age over 50.

_Plots 3-13_ are the proportional barplots of diabetes among different categories in the categorical variables. From the patterns in those plots, we may infer that `smoke`, `stroke`, and `heart_disease` are positively correlated with diabetes, while `income`, `education`, `sleep`, `exercise`, `alcohol`, and `health` have a negative relationship with diabetes. Among them, the most surprising result is that drinking more `alcohol` leads to a heavy drop in proportion of having `diabetes`, which may require future investigation.

More machine learning techniques are required to reach more rigorous conclusions about the relationships between the predictors and the response variable `diabetes`.

## 3.3 Correlation Matrix
```{r corr-matrix, echo=FALSE}
data_corr <- copy(data_downsampled)

data_corr[, diabetes := as.numeric(diabetes)]
data_corr[diabetes == 1, diabetes := 0]
data_corr[diabetes == 2, diabetes := 1]

data_numeric <- select_if(data_corr, is.numeric)
correlation_matrix <- cor(data_numeric)

diabetes_corr <-t(as.matrix(correlation_matrix[12, ]))
rownames(diabetes_corr) <- c("Diabetes")
diabetes_corr %>%
  kable(caption = "Table 4: Correlation Matrix Between all Variables") %>%
  kable_styling(html_font = "Cambria", full_width = FALSE)

# Compute the p-value for each pair
p.mat <- cor.mtest(correlation_matrix, conf.level= .95)
corrplot(correlation_matrix,
         method = "ellipse",
         type="lower",
         diag = FALSE,
         title = "Figure 2: Correlation Matrix Between all Variables",
         mar=c(0,0,1,0),
         p.mat = p.mat$p)
```

```{r eval=FALSE, include=FALSE}
correlation_matrix
```

From the `diabetes` row of the correlation matrix in _Table 4_, we can see that none of the variables have a very strong correlation with diabetes. However, among them, `age`, `bmi`, and `health` have a relatively strong correlation with diabetes (absolute value greater than 0.3). Additionally, `sleep` and `smoke` have a relatively weak correlation with diabetes (absolute value less than 0.1). Especially, `sleep` has the smallest relative correlation -0.0491838, which indicates that it may not be a good indicator of diabetes.

From the correlation plot in _Figure 2_, the correlation coefficients between `diabetes` and `age`, `income`, `exercise`, `health` are statistically significant, which indicates that they may be important risk factors. However, the correlation between `health` and three other variables, `income` and `education` are statistically significant. After checking the correlations, their absolute values are below 0.3, which seems fine. But VIF may be used to check multicollinearity after fitting the linear model.

## 3.4 Split the Dataset

Here, the dataset is splitted into 70% for training and 30% for testing. This is used to compare the performance of different models and select the model with best test accuracy.

```{r split, include=FALSE}
# Split the data into training and testing
set.seed(1007746003)
train<-sample(1:nrow(data_corr), round(0.7*nrow(data_corr)))
data_train<-data_corr[train,]
data_test<-data_corr[-train,]
dim(data_train)
dim(data_test)
```

```{r eval-func, include=FALSE}
# Define the function to measure the test accuracy and MSE of a given model
# Logistic model
test_logistic_acc <- function(model){

  model_pred <- predict(model, data_test)
  probs <- exp(model_pred)/(1+exp(model_pred))
  pred <- (probs > 0.5) * 1
  
  conf_mat <- table(true = data_test$diabetes, predicted = pred) %>%
    as.data.frame()
  
  # print(conf_mat)
  
  # Compute test accuracy
  num_correct <- with(conf_mat, sum(Freq[true == predicted]))
  acc <- num_correct / nrow(data_test)
  print(paste0("Test Accuracy: ", acc))
}

test_logistic_mse <- function(model){
  # Predict
  yhat <- predict(model, data_test)
  
  yhat <- exp(yhat)/(1+exp(yhat))
  
  # Compute MSE
  test_bind <- cbind(data_test, yhat)
  mse <- sum((as.numeric(test_bind$yhat) - test_bind$diabetes) ^ 2) / nrow(data_test)
  print(paste0("Test MSE: ", mse))
}

# Trees
test_tree_acc <- function(model){

  model_pred <- predict(model, data_test) %>%
    as.data.frame() %>%
    mutate(diabetes = ifelse(`1` > 0.5, 1, 0))
  pred <- model_pred$diabetes
  
  conf_mat <- table(true = data_test$diabetes, predicted = pred) %>%
    as.data.frame()
  
  # print(conf_mat)
  
  # Compute test accuracy
  num_correct <- with(conf_mat, sum(Freq[true == predicted]))
  acc <- num_correct / nrow(data_test)
  print(paste0("Test Accuracy: ", acc))
}

test_tree_mse <- function(model){
  # Predict
  yhat <- predict(model, data_test)
  
  # Compute MSE
  test_bind <- cbind(data_test, yhat)
  mse <- sum((as.numeric(test_bind$`1`) - test_bind$diabetes) ^ 2) / nrow(data_test)
  print(paste0("Test MSE: ", mse))
}

# Bagging & Random Forest
test_bagrf_acc <- function(model){

  pred <- predict(model, data_test)
  
  conf_mat <- table(true = data_test$diabetes, predicted = pred) %>%
    as.data.frame()
  
  # print(conf_mat)
  
  # Compute test accuracy
  num_correct <- with(conf_mat, sum(Freq[true == predicted]))
  acc <- num_correct / nrow(data_test)
  print(paste0("Test Accuracy: ", acc))
}

# Boosting
test_boost_acc <- function(model){

  model_pred <- predict(model, data_test, type="response") %>%
    as.data.frame() %>%
    mutate(diabetes = ifelse(. > 0.5, 1, 0))
  pred <- model_pred$diabetes
  
  conf_mat <- table(true = data_test$diabetes, predicted = pred) %>%
    as.data.frame()
  
  # print(conf_mat)
  
  # Compute test accuracy
  num_correct <- with(conf_mat, sum(Freq[true == predicted]))
  acc <- num_correct / nrow(data_test)
  print(paste0("Test Accuracy: ", acc))
}

test_boost_mse <- function(model, logistic = FALSE){
  # Predict
  yhat <- predict(model, data_test, type="response")
  
  # Compute MSE
  test_bind <- cbind(data_test, yhat)
  mse <- sum((as.numeric(test_bind$yhat) - test_bind$diabetes) ^ 2) / nrow(data_test)
  print(paste0("Test MSE: ", mse))
}
```


After the splitting, the training data contains 10021 rows, and the testing data has 4295 rows.

## 3.5 Logistic Regression Model

A logistic regression model between diabetes and all the other possible predictor variables is fitted to check whether the variable is statistically significant based on the p-value of the linear model. The summary of the model is as below.

```{r logistic, echo=FALSE, message=FALSE, warning=FALSE}
logit_model <- glm(diabetes ~ ., family = binomial, data_train)
# summ(logit_model)
tab_model(logit_model, show.se = TRUE, show.stat = TRUE, auto.label = FALSE,
          title = "Table 5: Summary of the Full Logistic Regression Model")
```

```{r eval=FALSE, include=FALSE}
test_logistic_acc(logit_model)
test_logistic_mse(logit_model)
```


- The $R^2$ Tjur is	0.338, indicating that approximately 33.8% of the variance in diabetes is explained by the predictor variables in the model, which is not very large for a model to predict `diabetes` well.
- **Intercept:** The intercept is 0 with a standard error of 0. This indicates the odds of the baseline group (when all other predictors are zero).
- **Race (Asian, Black, Hispanic, Other, American Indian/Alaskan Native):** These coefficients represent the odds ratio of the race having diabetes compared to the reference group White.
- **Sex (Male):** Being male is associated with a 1.3 times odds of having diabetes compared to being female.
- **Income:** Each one-unit increase in income is associated with an change by a factor of 0.94 in the odds of having diabetes. This indicates a negative relationship. 
- **BMI (Body Mass Index):** For each one-unit increase in BMI, the odds of having diabetes increase by a factor of 1.11, indicating a positive relationship.

The other variables can be interpreted from the table in similar ways.

Most coefficients are statistically significant at the 0.001 significance level with p-values <0.001, except for `raceAsian`, `raceOther`, `education`, `sleep`, `smoke`, and `stroke`. While `sleep` and `stroke` is significant at the 0.05 level, other variables have large p-values that indicate they don't have a statistically significant linear association with the log-odds of having diabetes. Especially `education` has an odds ratio of 1 with a p-value 0.959, which is very close to 1. This indicates there's no linear correlation between `education` and the log odds of `diabetes`. For similar reasons, `smoke` also lacks correlation with `diabetes`. Since the other variables are statistically significant, they may be important risk factors of `diabetes`.

The test accuracy of the model is 75.62%. The test MSE is about 0.1652.

```{r stepAIC, include=FALSE}
# Perform stepAIC
logit_model_AIC <- stepAIC(logit_model)
```

```{r evaluate-AIC, echo=FALSE, message=FALSE, warning=FALSE}
tab_model(logit_model_AIC, show.se = TRUE, show.stat = TRUE, auto.label = FALSE,
          title = "Table 6: Summary of the Logistic Regression Model After stepAIC")
```

```{r eval-logit, eval=FALSE, include=FALSE}
test_logistic_acc(logit_model_AIC)
test_logistic_mse(logit_model_AIC)
```


After performing stepAIC, the AIC reduced from 10031.23 to 10027.35, which is a small reduction. The variables `education` and `smoke` are removed as their coefficients are not statistically significant. The resulting model has all the predictor variables significant with level 0.05 except for the categories Asian and Other in `race`. The $R^2$ Tjur remains the same.

The test accuracy of the model is approximately 75.69% with a test mse of 0.1652, which are both slightly higher than the full model.

```{r multicollinearity, echo=FALSE}
VIF(logit_model_AIC) %>%
  kable(caption = "Table 7: Variance Inflation Factor (VIF)") %>%
  kable_paper("hover", full_width = FALSE)
```

Based on the correlation matrix in _Figure 2_, multicollinearity may be of concern. Therefore, the VIF of the variables are calculated in the AIC-selected logistic regression model. Since all values are close to 1 and far below 5 in _Table 7_, there is no existence of multicollinearity.

## 3.6 Classification Tree

A classification tree is fitted to predict `diabetes`, which is shown in _Figure 3_. Then, it is pruned based on the optimal complexity parameter. The complexity parameter table is shown in _Figure 4_ and the pruned tree is in _Figure 5_.

After pruning, there are much fewer nodes and number of splits in the tree. The variables used in the pruned tree are `age`, `alcohol`, `bmi`, `education`, `exercise`, `health`, `heart_disease`, `race`, and `sex`, which indicates that they are important predictors suggested by the tree.

The full tree has a test accuracy of 73.34% and an MSE of 0.1748. The test accuracy of the pruned tree is about 74.76% and the MSE is about 0.1737. Since the accuracy is lower and the MSE is higher than the logistic regression model, the pruned classification tree performs a bit worse than the AIC-selected logistic regression model.

```{r tree, echo=FALSE, warning=FALSE}
set.seed(1007746003)
# Fit the tree
tree <- rpart(
  diabetes ~.,
  data_train,
  method = "class",
  minsplit = 10,
  minbucket = 30,
  cp = 0,
  xval = 10
)

# Plot the full tree
rpart.plot(tree, main = "Figure 3: The Full Classification Tree")
```

```{r tree-prune, echo=FALSE}
# Plot the complexity parameter table for an rpart fit
cp <- plotcp(tree) + title(main = "Figure 4: The Complexity Parameter Table", line = 2.2)

# Find the optimal cp extracted from cptable
optimalcp <- tree$cptable[which.min(tree$cptable[, "xerror"]), "CP"]

# Prune the tree based on the optimal complexity parameter
tree_prune <- prune(tree, cp = optimalcp)

# Plot the pruned tree
rpart.plot(tree_prune, main = "Figure 5: The Pruned Classification Tree")
```

```{r eval-tree, eval=FALSE, include=FALSE}
test_tree_acc(tree)
test_tree_mse(tree)
printcp(tree)
tree$variable.importance
# summary(tree)

test_tree_acc(tree_prune)
test_tree_mse(tree_prune)
printcp(tree_prune)
```

## 3.7 Bagging

Bagging is used to predict diabetes. From the variable importance plot in _Figure 6_, the variables `bmi` and `age` have relatively high importance compared with the other variables. Therefore, `bmi` and `age` are important predictors of `diabetes` as suggested by bagging.

Bagging reaches a test accuracy of approximately 73.87%, which is lower than the pruned tree and GLM model.

```{r bag, echo=FALSE}
set.seed(1007746003)
# Predict diabetes using bagging
bag <- randomForest(
  as.factor(diabetes) ~ .,
  data_train,
  mtry = ncol(data_train) - 1,
  na.action = na.omit
)

# Construct the variable importance plot
varImpPlot(bag, main = "Figure 6: Variable Importance for Bagging")
```

```{r eval-bag, eval=FALSE, include=FALSE}
test_bagrf_acc(bag)
```

## 3.8 Random Forest

Random forest is used to predict diabetes. From the variable importance plot in _Figure 7_, the variables `bmi` and `age` have relatively high importance compared with the other variables, which is the same as the results of bagging.

Random forest has a test accuracy of about 75.55%, which is higher than the pruned tree and bagging but lower than the GLM model.

```{r rf, echo=FALSE}
set.seed(1007746003)
# Predict diabetes using random forest
rf <- randomForest(
  as.factor(diabetes) ~.,
  data_train,
  na.action = na.omit,
)

# Generate the variable importance plot
varImpPlot(
  rf,
  main = "Figure 7: Variable Importance for Random Forest"
)
```

```{r eval-rf, eval=FALSE, include=FALSE}
set.seed(1007746003)
test_bagrf_acc(rf)
```


## 3.9 Boosting

A gradient boosting machine is fitted to predict diabetes. From the _Figure 8_, the cross-validation error continues to decrease as the number of trees increases, but in a much slower speed when the number of trees is 3000. Therefore, additional boosting iteration are not performed for runtime-performance balance. 

Based on the variable importance plot in _Figure 9_, the variables `bmi`, `age`, and `health` have relatively high importance compared with the other variables, which contains the results of bagging and random forest.

The test accuracy of boosting is about 76.30%, which is the highest among all models so far. The test MSE of boosting is 0.1596, which is also the lowest among all previous models.

```{r boost, echo=FALSE, message=FALSE}
set.seed(1007746003)
boost <- gbm(
  diabetes ~.,
  data_train,
  distribution = "bernoulli",
  cv.folds = 5,
  class.stratify.cv = TRUE,
  n.trees = 3000
)

# Plot the cross-validation error as a function of the boosting iteration/trees
plot(boost$cv.error,  xlab = "Boosting Iteration/trees", ylab = "Cross-Validation Error", type = "l", col = "red", ylim = c(0, max(boost$cv.error) + 0.2), main = "Figure 8: Cross-Validation Error V.S. Boosting Iterations")
lines(boost$train.error, col = "blue")

# Generate the variable importance plot
tmp <- summary.gbm(boost, main = "Figure 9: Variable Importance for Boosting")
```

```{r eval-boost, eval=FALSE, include=FALSE}
# Evaluate the model
test_boost_acc(boost)
test_boost_mse(boost)
```

## 3.10 Extreme Gradient Boosting

An xgboost model is supposed to be trained to predict `diabetes`. To tune the maximum depth of the tree, the number of trees, and the learning rate, a grid search needs to be performed. During the process, a 10-fold cross-validation is used to evaluate the model performance.

The variable importance of extreme gradient boosting would be shown in _Figure 10_. The test accuracy and MSE for extreme gradient boosting would also be calculated through the code.

However, due to the large dataset and lack of computer power, the code used for extreme gradient boosting cannot terminate even after a few hours of running. Therefore, the results and performance of the xgboost model are left as the future work to be done.

```{r xgb, eval=FALSE, warning=FALSE, include=FALSE}
set.seed(1007746003)
train_control = trainControl(method = "cv", number = 10, search ="grid")

tune_grid <- expand.grid(max_depth = c(3, 5, 10),
                         nrounds = (3:7) * 500,
                         eta = c(0.001, 0.01, 0.1, 0.3),
                         gamma = 0,
                         subsample = 1,
                         min_child_weight = 1,
                         colsample_bytree = 0.6
                         )

xgb <- caret::train(
  diabetes ~ .,
  data = data_train,
  na.action = na.omit,
  method = "xgbTree",
  trControl = train_control,
  tuneGrid = tune_grid,
  verbosity = 0
)

# Summary
plot(xgb)

# Generate the variable importance plot
varimp <- varImp(xgb)
plot(varimp, main = "Figure 10: Variable Importance Plot for XGBoost")

# Evaluate the model
test_boost_acc(xgb)
test_boost_mse(xgb)
```

# 4. Conclusions and Summary

The _Table 8_ below contains the selected important predictors, test accuracy, and test MSE for each of the machine learning models fitted.

<div align="center">

## Table 8: Summary of All Fitted Models

</div>

|           | AIC-Logistic Regression | Full Classification Tree | Pruned Classification Tree | Bagging | Random Forest | Boosting |
|-----------|:---:|:---:|:---:|:---:|:---:|:---:|
| race      |  ✓   |    ✓     |      ✓      |    ✓     |  ✓  |    ✓      |
| sex       |   ✓      |   ✓      |     ✓       |         |    |          |
| age       |   ✓      |   ✓      |     ✓       |     ✓    |  ✓  |    ✓      |
| education |        |    ✓     |      ✓      |     ✓    | ✓   |          |
| income    |   ✓      |   ✓      |           |    ✓     | ✓   |    ✓      |
| sleep     |   ✓      |    ✓     |           |         |    |          |
| smoke     |        |     ✓    |           |         |    |          |
| bmi       |   ✓      |   ✓      |     ✓       |    ✓     |  ✓  |   ✓       |
| exercise  |   ✓      |    ✓     |    ✓   |         |    |          |
| stroke    |    ✓     |         |           |         |    |          |
| heart_disease | ✓  |     ✓    |      ✓      |         |    |    ✓      |
| alcohol   |    ✓     |   ✓      |     ✓   |         |    |          |
| health    |   ✓      |   ✓      |     ✓       |    ✓     | ✓   |     ✓     |
| Test Accuracy    |   75.69%      |   73.34%      |     74.76%       |    73.87%     | 75.55%   |     76.30%     |
| Test MSE    |   0.1652      |   0.1748      |     0.1737       |         |    |     0.1596     |

Based on _Table 8_, the test accuracies among all models are all around 75% and the test MSEs are all about 0.165. Among them, boosting model has the highest test accuracy and lowest test MSE, which indicates that it is the best model among all the models fitted here.

Among all the predictors, `race`, `age`, `bmi`, and `health` are considered as important in all the models. `education` has high variable importance in all models except the AIC-selected logistic regression model. Therefore, those 5 variables may be most predictive of `diabetes` as suggested by the fitted models.

However, the models fitted using the survey data can only suggest correlations between the predictors and `diabetes` but cannot prove causal relationships. We cannot conclude which is the cause and which is the effect. Therefore, we are still uncertain about the risk factors of `diabetes` but at least we find some important predictors and can predict `diabetes` at an accuracy of 76.30%.

Since the data is based on self-reported surveys, there may be flaws in the answers. Additionally, many other risk factors are worth researching. Therefore, more accurate scientific research data needs to be analyzed to get more reliable results.

I hope that this research can offer some insights into how we can prevent ourselves from having Type 2 Diabetes.

# 5. References
